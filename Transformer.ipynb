{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-layer architecture for next token prediction task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports and Utility functions\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import numpy as np\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "import flax.serialization\n",
    "\n",
    "# Define utility functions for attention mechanism\n",
    "def causal_mask(size):\n",
    "    mask = np.tril(np.ones((size, size), dtype=np.bool_), k=0)\n",
    "    return jnp.array(mask)\n",
    "\n",
    "def cross_entropy_loss(logits, labels):\n",
    "    log_probs = jax.nn.log_softmax(logits)\n",
    "    return -jnp.sum(labels * log_probs) / labels.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    embed_dim: int\n",
    "    num_heads: int\n",
    "\n",
    "    def setup(self):\n",
    "        assert self.embed_dim % self.num_heads == 0, \"Embedding dimension must be divisible by number of heads.\"\n",
    "        self.head_dim = self.embed_dim // self.num_heads\n",
    "        self.qkv = nn.Dense(features=self.embed_dim * 3, use_bias=False)\n",
    "        self.out = nn.Dense(features=self.embed_dim)\n",
    "\n",
    "    def __call__(self, x, mask=None):\n",
    "        batch_size, seq_length, _ = x.shape\n",
    "        qkv = self.qkv(x)\n",
    "        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3, self.head_dim)\n",
    "        qkv = qkv.transpose((2, 0, 1, 3, 4))  # (num_heads, batch_size, seq_length, 3, head_dim)\n",
    "        q, k, v = qkv[:, :, :, 0, :], qkv[:, :, :, 1, :], qkv[:, :, :, 2, :]\n",
    "\n",
    "        attn_weights = jnp.einsum('hbqd,hbkd->hbqk', q, k) / jnp.sqrt(self.head_dim)\n",
    "\n",
    "        if mask is not None:\n",
    "            attn_weights = jnp.where(mask[None, None, :, :], attn_weights, -1e10)\n",
    "\n",
    "        attn_weights = jax.nn.softmax(attn_weights, axis=-1)\n",
    "        attn_output = jnp.einsum('hbqk,hbvd->hbqd', attn_weights, v)\n",
    "        attn_output = attn_output.transpose((1, 2, 0, 3))  # (batch_size, seq_length, num_heads, head_dim)\n",
    "        attn_output = attn_output.reshape(batch_size, seq_length, self.embed_dim)\n",
    "\n",
    "        return self.out(attn_output)\n",
    "\n",
    "\n",
    "class TransformerDecoderLayer(nn.Module):\n",
    "    embed_dim: int\n",
    "    num_heads: int\n",
    "\n",
    "    def setup(self):\n",
    "        self.self_attn = MultiHeadSelfAttention(embed_dim=self.embed_dim, num_heads=self.num_heads)\n",
    "        self.ln = nn.LayerNorm()\n",
    "\n",
    "    def __call__(self, x, mask=None):\n",
    "        attn_output = self.self_attn(x, mask=mask)\n",
    "        x = x + attn_output\n",
    "        x = self.ln(x)\n",
    "        return x\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    vocab_size: int\n",
    "    layer_dims: list\n",
    "    num_heads: list\n",
    "\n",
    "    def setup(self):\n",
    "        self.embedding = nn.Embed(num_embeddings=self.vocab_size, features=self.layer_dims[0])\n",
    "        self.layers = [TransformerDecoderLayer(embed_dim=layer_dim, num_heads=num_heads) \n",
    "                       for layer_dim, num_heads in zip(self.layer_dims, self.num_heads)]\n",
    "        self.ln = nn.LayerNorm()\n",
    "\n",
    "    def __call__(self, x, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask=mask)\n",
    "        x = self.ln(x)\n",
    "        return x\n",
    "\n",
    "class NextTokenPredictor(nn.Module):\n",
    "    vocab_size: int\n",
    "    layer_dims: list\n",
    "    num_heads: list\n",
    "\n",
    "    def setup(self):\n",
    "        self.decoder = TransformerDecoder(\n",
    "            vocab_size=self.vocab_size,\n",
    "            layer_dims=self.layer_dims,\n",
    "            num_heads=self.num_heads\n",
    "        )\n",
    "        self.out = nn.Dense(features=self.vocab_size)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        seq_length = x.shape[1]\n",
    "        mask = causal_mask(seq_length)\n",
    "        decoder_output = self.decoder(x, mask=mask)\n",
    "        logits = self.out(decoder_output)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model definition\n",
    "\n",
    "S = 5  # Cardinality of the alphabet\n",
    "T = 25  # Sequence length\n",
    "m1 = 2  # Heads in the first layer\n",
    "m2 = 1  # Heads in the second layer\n",
    "d_0 = S + T  # Embedding dimension\n",
    "d_1 = (1 + m1) * d_0  # Dimension of the first layer\n",
    "d_2 = (1 + m2) * d_1  # Dimension of the second layer\n",
    "\n",
    "vocab_size = S\n",
    "layer_dims = [d_0, d_1, d_2]  # Embedding dimensions for each layer\n",
    "num_heads = [2, 1]  # Number of heads for each layer\n",
    "\n",
    "model = NextTokenPredictor(\n",
    "    vocab_size=vocab_size,\n",
    "    layer_dims=layer_dims,\n",
    "    num_heads=num_heads\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of loaded sequences: (1000, 25)\n",
      "Shape of embedded sequences: (1000, 25, 30)\n"
     ]
    }
   ],
   "source": [
    "# Data importing (Tri-grams)\n",
    "# Load sequences from file\n",
    "sequences = np.load('sequences.npy')\n",
    "\n",
    "# Check the shape of the loaded sequences\n",
    "print(\"Shape of loaded sequences:\", sequences.shape)\n",
    "\n",
    "# Embedding\n",
    "embedded_sequences = np.zeros((sequences.shape[0], sequences.shape[1], d_0))\n",
    "for i in range(sequences.shape[0]):\n",
    "    for j in range(sequences.shape[1]):\n",
    "        embedded_sequences[i, j, sequences[i, j]] = 1\n",
    "        embedded_sequences[i, j, S + j] = 1\n",
    "print(\"Shape of embedded sequences:\", embedded_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add got incompatible shapes for broadcasting: (1, 25, 30), (1, 25, 90).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Initialize model and optimizer state\u001b[39;00m\n\u001b[1;32m     22\u001b[0m rng \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m params \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minit(rng, jnp\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, T), dtype\u001b[38;5;241m=\u001b[39mjnp\u001b[38;5;241m.\u001b[39mint32))\n\u001b[1;32m     24\u001b[0m optimizer_state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39minit(params)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[12], line 79\u001b[0m, in \u001b[0;36mNextTokenPredictor.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     77\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     78\u001b[0m mask \u001b[38;5;241m=\u001b[39m causal_mask(seq_length)\n\u001b[0;32m---> 79\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[1;32m     80\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout(decoder_output)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[12], line 59\u001b[0m, in \u001b[0;36mTransformerDecoder.__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     57\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 59\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer(x, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[1;32m     60\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[12], line 41\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     40\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(x, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[0;32m---> 41\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m attn_output\n\u001b[1;32m     42\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:265\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    263\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 265\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m binary_op(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.12/site-packages/jax/_src/numpy/ufuncs.py:102\u001b[0m, in \u001b[0;36m_maybe_bool_binop.<locals>.fn\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(x1, x2, \u001b[38;5;241m/\u001b[39m):\n\u001b[1;32m    101\u001b[0m   x1, x2 \u001b[38;5;241m=\u001b[39m promote_args(numpy_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, x1, x2)\n\u001b[0;32m--> 102\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lax_fn(x1, x2) \u001b[38;5;28;01mif\u001b[39;00m x1\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_ \u001b[38;5;28;01melse\u001b[39;00m bool_lax_fn(x1, x2)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax/lib/python3.12/site-packages/jax/_src/lax/lax.py:1665\u001b[0m, in \u001b[0;36mbroadcasting_shape_rule\u001b[0;34m(name, *avals)\u001b[0m\n\u001b[1;32m   1663\u001b[0m       result_shape\u001b[38;5;241m.\u001b[39mappend(non_1s[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1664\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1665\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got incompatible shapes for broadcasting: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1666\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m,\u001b[38;5;250m \u001b[39mshapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[0;31mTypeError\u001b[0m: add got incompatible shapes for broadcasting: (1, 25, 30), (1, 25, 90)."
     ]
    }
   ],
   "source": [
    "## Training\n",
    "import os\n",
    "\n",
    "# Directory to save model parameters\n",
    "save_dir = \"saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Lists to store training loss and model parameters\n",
    "training_losses = []\n",
    "model_params_list = []\n",
    "\n",
    "num_epochs = 1000\n",
    "num_batches = 16\n",
    "batch_size = embedded_sequences.shape[0] // num_batches\n",
    "\n",
    "# Define optimizer with cosine decay schedule\n",
    "num_train_steps = num_epochs * num_batches\n",
    "lr_schedule = optax.cosine_decay_schedule(1.0, num_train_steps)\n",
    "optimizer = optax.chain(optax.adam(learning_rate=lr_schedule), optax.clip_by_global_norm(1.0))\n",
    "\n",
    "# Initialize model and optimizer state\n",
    "rng = random.PRNGKey(0)\n",
    "params = model.init(rng, jnp.zeros((1, T), dtype=jnp.int32))\n",
    "optimizer_state = optimizer.init(params)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        # Get batch\n",
    "        batch_sequences = embedded_sequences[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "        batch_targets = embedded_sequences[batch_idx * batch_size + 1 : (batch_idx + 1) * batch_size + 1]\n",
    "        \n",
    "        # Compute gradients and loss\n",
    "        def loss_fn(params):\n",
    "            logits = model.apply(params, batch_sequences)\n",
    "            loss = cross_entropy_loss(logits, batch_targets)\n",
    "            return loss, logits\n",
    "        \n",
    "        grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "        (loss, _), grads = grad_fn(params)\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        # Update parameters\n",
    "        updates, optimizer_state = optimizer.update(grads, optimizer_state)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "    \n",
    "    # Calculate average epoch loss\n",
    "    avg_epoch_loss = epoch_loss / num_batches\n",
    "    training_losses.append(avg_epoch_loss)\n",
    "\n",
    "    # Save model parameters\n",
    "    if (epoch + 1) % 25 == 0:\n",
    "        model_params_list.append(params)\n",
    "        model_path = os.path.join(save_dir, f\"model_epoch_{epoch+1}.params\")\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            f.write(flax.serialization.to_bytes(params))\n",
    "    \n",
    "    # Print epoch loss\n",
    "    print(f\"Epoch {epoch+1}, Loss: {avg_epoch_loss}\")\n",
    "\n",
    "# Save training losses to file\n",
    "losses_path = os.path.join(save_dir, \"training_losses.npy\")\n",
    "np.save(losses_path, np.array(training_losses))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
